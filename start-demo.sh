#!/bin/bash

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ðŸš€ Cafe Language Learning - AI Demo Startup"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# Store the script directory
SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
cd "$SCRIPT_DIR"

# Check if Ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama not found!"
    echo ""
    echo "ðŸ“¦ Please install Ollama:"
    echo "   Mac/Linux: curl -fsSL https://ollama.com/install.sh | sh"
    echo "   Windows:   https://ollama.com/download/windows"
    echo ""
    exit 1
fi

# Check if Python 3 is installed
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 not found!"
    echo "   Please install Python 3.8 or higher"
    exit 1
fi

# Start Ollama service if not running
if ! pgrep -x "ollama" > /dev/null; then
    echo "ðŸ“¦ Starting Ollama service..."
    ollama serve > /tmp/ollama.log 2>&1 &
    sleep 3
fi

# Check if Qwen3:8B is available
echo "ðŸ” Checking for Qwen3:8B model..."
if ! ollama list | grep -q "qwen3:8b"; then
    echo "âš ï¸  Qwen3:8B not found. Downloading..."
    echo "    Size: 5.2GB - This will take 3-5 minutes"
    echo ""
    ollama pull qwen3:8b
    if [ $? -ne 0 ]; then
        echo "âŒ Failed to download Qwen3:8B"
        exit 1
    fi
fi
echo "âœ… Qwen3:8B ready!"

# Check if Python dependencies are installed
echo "ðŸ” Checking Python dependencies..."
if ! python3 -c "import flask, faster_whisper, ollama" 2>/dev/null; then
    echo "âš ï¸  Installing Python dependencies..."
    pip3 install -q -r requirements.txt
    if [ $? -ne 0 ]; then
        echo "âŒ Failed to install dependencies"
        echo "   Try manually: pip3 install -r requirements.txt"
        exit 1
    fi
fi
echo "âœ… Python dependencies installed!"

# Kill any existing backend on port 5000
if lsof -Pi :5000 -sTCP:LISTEN -t >/dev/null 2>&1; then
    echo "âš ï¸  Port 5000 already in use. Killing existing process..."
    kill $(lsof -t -i:5000) 2>/dev/null
    sleep 1
fi

# Kill any existing HTTP server on port 8000
if lsof -Pi :8000 -sTCP:LISTEN -t >/dev/null 2>&1; then
    echo "âš ï¸  Port 8000 already in use. Killing existing process..."
    kill $(lsof -t -i:8000) 2>/dev/null
    sleep 1
fi

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… All systems ready!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# Start backend service in background
echo "ðŸ–¥ï¸  Starting AI backend service (Flask + Whisper + Qwen3)..."
python3 backend_service.py > /tmp/backend.log 2>&1 &
BACKEND_PID=$!
sleep 3

# Check if backend started successfully
if ! ps -p $BACKEND_PID > /dev/null; then
    echo "âŒ Backend failed to start. Check /tmp/backend.log for details"
    cat /tmp/backend.log
    exit 1
fi
echo "âœ… Backend running (PID: $BACKEND_PID)"

# Start HTTP server in background for frontend
echo "ðŸŒ Starting HTTP server for frontend..."
python3 -m http.server 8000 > /tmp/httpserver.log 2>&1 &
HTTP_PID=$!
sleep 2

if ! ps -p $HTTP_PID > /dev/null; then
    echo "âŒ HTTP server failed to start"
    kill $BACKEND_PID 2>/dev/null
    exit 1
fi
echo "âœ… HTTP server running (PID: $HTTP_PID)"

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ðŸŽ‰ Demo is ready!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ðŸ“± Frontend:  http://localhost:8000"
echo "ðŸ¤– Backend:   http://localhost:5000"
echo "ðŸ’¬ AI Model:  Qwen3:8B (multilingual)"
echo "ðŸŽ¤ Speech:    Whisper (medium)"
echo ""
echo "ðŸŒ Opening demo in browser..."
echo ""

# Open browser
if [[ "$OSTYPE" == "darwin"* ]]; then
    open http://localhost:8000/ai-chat-demo.html
elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
    xdg-open http://localhost:8000/ai-chat-demo.html
fi

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ðŸ“Œ Demo is running!"
echo ""
echo "   Press Ctrl+C to stop all services"
echo ""
echo "   Logs:"
echo "   - Backend:  tail -f /tmp/backend.log"
echo "   - Ollama:   tail -f /tmp/ollama.log"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# Cleanup function
cleanup() {
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "ðŸ›‘ Shutting down demo..."
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

    # Kill backend
    if ps -p $BACKEND_PID > /dev/null 2>&1; then
        echo "   Stopping backend (PID: $BACKEND_PID)..."
        kill $BACKEND_PID 2>/dev/null
    fi

    # Kill HTTP server
    if ps -p $HTTP_PID > /dev/null 2>&1; then
        echo "   Stopping HTTP server (PID: $HTTP_PID)..."
        kill $HTTP_PID 2>/dev/null
    fi

    # Optionally stop Ollama (commented out - you might want to keep it running)
    # echo "   Stopping Ollama..."
    # pkill -f "ollama serve"

    echo ""
    echo "âœ… All services stopped"
    echo "ðŸ‘‹ Thanks for using the demo!"
    echo ""
    exit 0
}

# Set up trap for cleanup
trap cleanup INT TERM

# Wait for user interrupt
wait
